{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "CQGc8GU_ShQS",
        "outputId": "8f994a64-04f1-478b-9ed4-4e265ae10a64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '●' (U+25CF) (<ipython-input-1-449f3802d108>, line 19)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-449f3802d108>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    ● Ionosphere Dataset (csv).\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '●' (U+25CF)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"DML TASK1.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1wjqoWXflkNr6Fkv2zXPT0Ur0u9ptFq5X\n",
        "\n",
        "**1.MLP for Binary Classification**\n",
        "\"\"\"\n",
        "\n",
        "#1.MLP for Binary Classification\n",
        "use the Ionosphere binary (two-class) classification dataset to demonstrate an MLP for\n",
        "binary classification.\n",
        "This dataset involves predicting whether a structure is in the atmosphere or not, given radar\n",
        "returns.\n",
        "The dataset will be downloaded automatically using Pandas, but you can learn more about\n",
        "it here.\n",
        "● Ionosphere Dataset (csv).\n",
        "● Ionosphere Dataset Description (csv).\n",
        "You can use a LabelEncoder to encode the string labels to integer values 0 and 1. The\n",
        "model will be fit on 67% of the data, and the remaining 33% will be used for evaluation, split\n",
        "using the train_test_split() function.\n",
        "It is good practice to use ‘relu‘ activation with a ‘he_normal‘ weight initialization. This\n",
        "combination goes a long way in overcoming the problem of vanishing gradients when\n",
        "training deep neural network models.\n",
        "The model predicts the probability of class 1 and uses the sigmoid activation function. The\n",
        "model is optimized using the adam version of stochastic gradient descent and seeks to\n",
        "minimize the cross-entropy loss\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv\n",
        "\n",
        "# mlp for binary classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
        "# evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)\n",
        "# make a prediction\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,\n",
        "       -0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat)\n",
        "\n",
        "\"\"\"**2.MLP for Multiclass Classification**\"\"\"\n",
        "\n",
        "#2.MLP for Multiclass Classification\n",
        "We will use the Iris flowers multiclass classification dataset to demonstrate an MLP for\n",
        "multiclass classification.\n",
        "This problem involves predicting the species of iris flower given measures of the flower.\n",
        "The dataset will be downloaded automatically using Pandas, but you can learn more about\n",
        "it here.\n",
        "● Iris Dataset (csv).\n",
        "● Iris Dataset Description (csv).\n",
        "Given that it is a multiclass classification, the model must have one node for each class in\n",
        "the output layer and use the softmax activation function. The loss function is the\n",
        "‘sparse_categorical_crossentropy‘, which is appropriate for integer encoded class labels\n",
        "(e.g., 0 for one class, 1 for the next class, etc.)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\n",
        "\n",
        "# mlp for multiclass classification\n",
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
        "# evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)\n",
        "# make a prediction\n",
        "row = [5.1,3.5,1.4,0.2]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))\n",
        "\n",
        "\"\"\"**3.MLP for Regression**\"\"\"\n",
        "\n",
        "#3.MLP for Regression\n",
        "Use the Boston housing regression dataset to demonstrate an MLP for regression\n",
        "predictive modeling.\n",
        "This problem involves predicting house value based on the properties of the house and\n",
        "neighborhood.\n",
        "The dataset will be downloaded automatically using Pandas, but you can learn more about\n",
        "it here.\n",
        "● Boston Housing Dataset (csv).\n",
        "● Boston Housing Dataset Description (csv).\n",
        "This is a regression problem that involves predicting a single numerical value. As such, the\n",
        "output layer has a single node and uses the default or linear activation function (no\n",
        "activation function). The mean squared error (mse) loss is minimized when fitting the model.\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv\n",
        "\n",
        "# mlp for regression\n",
        "from numpy import sqrt\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
        "# evaluate the model\n",
        "error = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n",
        "# make a prediction\n",
        "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat)\n",
        "\n",
        "\"\"\"**#4.Deep Learning CNN for Fashion-MNIST**\"\"\"\n",
        "\n",
        "#4.Deep Learning CNN for Fashion-MNIST\n",
        "Clothing Classification\n",
        "The Fashion-MNIST clothing classification problem is a new standard dataset used in\n",
        "computer vision and deep learning.\n",
        "Dataset : https://github.com/zalandoresearch/fashion-mnist\n",
        "\n",
        "!wget https://github.com/zalandoresearch/fashion-mnist\n",
        "\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()\n",
        "print(\"Training images shape:\",train_images.shape)\n",
        "print(\"Training labels shape:\",train_labels.shape)\n",
        "print(\"Test images shape:\",test_images.shape)\n",
        "print(\"Test labels shape:\",test_labels.shape)\n",
        "class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag',\n",
        "             'Ankle boot']\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0],cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.title(f\"Class:{class_names[train_labels[0]]}\")\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}